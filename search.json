[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mapping the distribution of the White-tailed deer in Minnesota",
    "section": "",
    "text": "Welcome\nIn this tutorial, you will create a habitat suitability map of the white-tailed deer (Odocoileus virginianus) in Minnesota, USA. You do this by combining information about the habitat preferences of the white-tailed deer and existing coarse scale data of deer densities.\n\nThe tutorial aims to introduce some common and perhaps some less common functions and techniques you can use to carry out a simple multi-criteria analysis in GRASS GIS.\n\nFor those not familiar with GRASS GIS, it offers a wide range of tools for terrain and ecosystem modeling, hydrology, management, and analysis of geospatial data, and the processing of satellite and aerial imagery. It comes with a temporal framework for advanced time series processing and a Python API for rapid geospatial programming. Read more here…\nThis tutorial provides a step-by-step explanation of the analysis, with code you can run from the command line or as a Python script. The functions can also be invoked from the GUI menu or Tools tab if you prefer that. For QGIS users, note that most grass functions used in this tutorial are also available in QGIS. If you are more familiar with ArcGIS, check out the page GRASS GIS for ArcGIS users to get a grasp of the main GRASS GIS concepts you should know about.\n\n\n\n\n1. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "1_requirements.html",
    "href": "1_requirements.html",
    "title": "1  Getting started",
    "section": "",
    "text": "1.1 Interface\nThis tutorial is for users who are familiar with GRASS GIS. If you are not, you are encouraged to first check out the General overview, the First time users page, and the list of tutorials on the GRASS GIS website. And for those who are well versed in GIS, but new to GRASS GIS, have a look at these tips.\nIn the tutorial, you’ll be introduced to several functions. The tutorial will show how to use the functions, but will not (always) explain the settings and parameters. Instead, each time a function is used, a link is provided to the corresponding help page. These help pages are quite good, and you are encouraged to read them to fully understand the choices made in the tutorial.\nThe examples in this tutorial show you how to run functions from the terminal or the Console tab of the GUI. If you prefer to run the analysis in Python, you can use the GRASS Python Scripting Library from the Python command line (go to the Python tab) or using the Python editor (Figure 1.1). The first step is to import the grass.script library. In the code below, it is imported as gs. Next, you can run GRASS GIS functions using the run_command. The general syntax is:\nFor example, you can use the following code to print the region settings (extent, resolution) and save them under the name ‘myregion’.\nThere are also other functions besides run_command, including read_command, write_command and parse_command. Read more about the Python interface to scripting and the differences between the functions in the manual.\nFor your analyses, you are encouraged to use the command line or Python code, as these facilitate reproducibility, make it easy to automate your work, and quickly test small changes and tweaks. However, using the GUI can be a good way to further explore the various options a function offers. And note that it always shows you the corresponding code, which you can copy for later use.\nAll functions can also be invoked from the GUI menu or Tools tab. Alternatively, you can type in the name of the function in the Console tab or in the terminal and hit enter. This will open the function’s window (Figure 1.1).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "1_requirements.html#interface",
    "href": "1_requirements.html#interface",
    "title": "1  Getting started",
    "section": "",
    "text": "Figure 1.1: Run code from the console (1) or terminal (4). Run Python code from the Python console (2) or Python editor (3).\n\n\n\n\n\n\n\n\nimport grass.script as gs\ngs.run_command(\n    \"module.name\",\n    option1=\"...\",\n    option2=\"...\",\n    flags=\"flagletters\",\n)\n\n\n\n\n\n\n\n\nimport grass.script as gs\ngs.run_command('g.region', flags='p', save=\"myregion\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "1_requirements.html#sec-datamanagement",
    "href": "1_requirements.html#sec-datamanagement",
    "title": "1  Getting started",
    "section": "1.2 Database",
    "text": "1.2 Database\nGRASS GIS works with special databases, which you can access from the Data Catalog. The GRASS GIS has a hierarchical structure consisting of Database , Project  and Mapset . Note that in GRASS GIS versions prior to 8.4, Projects were called Locations. If you are not familiar with the GRASS GIS database, you are encouraged to read this overview.\nA project is defined by its coordinate reference system (CRS). This means that all the data it holds is in the same CRS. In general, if your data comes in a specific CRS, you should create a Project corresponding to that CRS. Alternatively, you can reproject data on-the-fly during importing. Read this page for different options.\n\n\n\n\n\n\n\n\nFigure 1.2: GRASS GIS Database structure as visible to the user\n\n\n\nEach project can have many Mapset, which contain the actual data, mostly geospatial data, referred to as maps in GRASS GIS. Mapsets provide a way to organize maps transparently, as well as a tool for isolating different tasks to prevent data loss. When creating a new Project, GRASS GIS automatically creates a special Mapset called PERMANENT where the core data for the project can be stored. This is the only mapset that is obligatory. Read the GRASS GIS Quickstart to learn more.\n\n\n\n\nFor this tutorial, create a new Project with the coordinate reference system (CRS) NAD83 with projection UTM zone 15N (EPSG 26915). The first video shows you how to add a new Project to an existing GRASS GIS database. The second video shows you how to create a new GRASS GIS database, Project and Mapset.\n\n\n\n\n\n\n\n\n\nNow that you have created a Project, create a mapset WhitetailedDeer. You can create a new mapset in the current mapset using the button  in the Data catalog toolbar or using the menu Settings → GRASS working environments → Create new mapset. Alternatively, you can create a new mapset from the command line.\n\n\n\n\ng.mapset -c mapset=WitetailedDeer\n\n\nimport grass.script as gs\ngs.run_command(\"g.mapset\", flags=\"c\", mapset=\"WhitetailedDeer\")\n\n\n\nYou’ll see that when you create a new mapset, GRASS GIS will switch automatically to that mapset. That means that if you run an analysis, the results will be stored in the new mapset.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "1_requirements.html#region-mask",
    "href": "1_requirements.html#region-mask",
    "title": "1  Getting started",
    "section": "1.3 Region & Mask",
    "text": "1.3 Region & Mask\nThe region is an important concept in GRASS GIS, that allows you to fully control the extent and resolution of your raster computations. All raster computations will be performed in the specified extent and with the given resolution to ensure consistency. This makes it easy to subset larger extent data for quicker testing of analysis, or to run an analysis of specific regions given by, e.g., administrative units.\n\n\n\n\n\n\n\n\nFigure 1.3: When a MASK is set, parallel processing is disabled. That means that if you want to use for example the r.mfilter using multiple threads, and you want to limit the computation to a certain area, you need to create an intermediate layer first, and use that as input.\n\n\n\nAnother important tool is the MASK. This is a raster map that defines areas to include or exclude in analyses or operations. A MASK is typically created from an existing raster map using the r.mask function. Once a MASK is set, any raster operation (e.g., map algebra, resampling, or any raster processing) will only consider the cells within the masked area. Operations ignore cells outside this area as if they were null.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "1_requirements.html#sec-datasets",
    "href": "1_requirements.html#sec-datasets",
    "title": "1  Getting started",
    "section": "1.4 Data Minnesota",
    "text": "1.4 Data Minnesota\nFor this tutorial, the analysis will be carried out for Minnesota. Alternatively, to make the analysis run faster, you can limit the areas for which you carry out the analysis. In that case, skip this section, and go to Section 1.5.\nFor this tutorial, the assumption is that you copy all required input files to the working directory. On the command line, use the cd command to set the working directory. In Python, you can change the working directory using the os.chdir command. See here for how to do this.\n\n1.4.1 Boundary layer\nFirst step is to download the vector layer with the state boundary of Minnesota. Go to the download page, download the OGC GeoPackage from there and unzip it to your working directory. Next, use v.in.ogr to import the layer in GRASS GIS.\n\n\n\n\n# Import\nv.in.ogr input=bdry_state_of_minnesota.gpkg \\\nlayer=state_of_minnesota output=Minnesota_bdry\n\n\n# Import\ngs.run_command(\n    \"v.in.ogr\",\n    input=\"bdry_state_of_minnesota.gpkg\",\n    layer=\"state_of_minnesota\",\n    output=\"Minnesota_bdry\",\n)\n\n\n\nNow, set the region to match the extent of the vector layer you just imported. This will help you to limit the import of other layers to the extent of Minnesota.\n\n\n\n\n# Set the region\ng.region vector=Minnesota_bdry\n\n\n# Set the region\ngs.run_command(\"g.region\", vector=\"Minnesota_bdry\")\n\n\n\n\n\n1.4.2 Land cover\nOne of the main data layers you are going to work with is the National Land Cover Database (NLCD) of the USA. You can download the NLCD layer for Minnesota from the Minnesota GIS portal. There are :various versions. The examples in this tutorial are based on the NLCD for 2016, which you can download here as a geoTIF raster layer.\nNext, use the functions r.in.gdal to import the raster data in GRASS GIS. The raster layer covers an area larger than Minnesota. You should therefore set the -r flag to limit the import to the computational region. Note that because r.in.gdal does not change the resolution and alignment of the original layer, the extent of the imported layer may be slightly larger than the regional extent.\n\n\n\n\n# Import land use map\nr.in.gdal input=NLCD_2016_Land_Cover.tif output=NLCD_2016\n\n# Import the boundary maps\nr.in.ogr input=bdry_state_of_minnesota.gpkg \\\nlayer=state_of_minnesota output=Minnesota_state\n\n\n# Import land use map\ngs.run_command(\n    \"r.in.gdal\",\n    flags=\"r\",\n    input=\"NLCD_2016_Land_Cover.tif\",\n    output=\"NLCD_2016\",\n)\n\n\n\nUse the g.region function again to set the region to exactly match the extent and resolution of the NLCD_2016 raster layer. This will ensure that all subsequent raster calculations will be carried out using the right resolution and extent.\n\n\n\n\ng.region -a raster=NLCD_2016\n\n\ngs.run_command(\n    \"g.region\",\n    flags=\"a\",\n    raster=\"NLCD_2016\",\n)\n\n\n\n\n\n1.4.3 Infrastructure\nYou will also need a dataset of the infrastructure and buildings of Minnesota. For this tutorial, you’ll use the Openstreetmap data. Geofrabric offers a convenient free download server where you can download OSM data for the individual USA states.\nDownload the zip file with shapefiles for Minnesota and unzip the layers in your working directory. The zip files include various Shapefiles. Import the layers gis_osm_buildings_a_free_1, gis_osm_railways_a_free_1, gis_osm_roads_a_free_1 and gis_osm_traffic_a_free_1. The data is in latlon (EPSG 4326) so you need to use the r.import function. This will reproject your data on-the-fly during import.\n\n\n\n\nv.import input=gis_osm_buildings_a_free_1.shp output=buildings\nv.import input=gis_osm_railways_free_1.shp output=railways\nv.import input=gis_osm_roads_free_1.shp output=railways\nv.import input=gis_osm_traffic_a_free_1.shp output=railways\n\n\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_buildings_a_free_1.shp\",\n    output=\"buildings\",\n)\n\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_railways_free_1.shp\",\n    output=\"railways\",\n)\n\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_roads_free_1.shp\",\n    output=\"roads\",\n)\n\n\ngs.run_command(\n    \"v.import\", input=\"gis_osm_traffic_a_free_1.shp\", output=\"traffic\"\n)\n\n\n\nIn the rest of the tutorial, the analyses are carried out for the whole state, at a resolution of 30m. If that is OK, skip the next section. If you want to run the analysis for a smaller area, follow the example in the next section (Section 1.5).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "1_requirements.html#sec-subsection",
    "href": "1_requirements.html#sec-subsection",
    "title": "1  Getting started",
    "section": "1.5 Data counties",
    "text": "1.5 Data counties\nSome steps of the analysis will take quite some time. To make the analysis run faster, you can set a lower resolution and/or define a smaller region for which we carry out the analysis. This section shows you how to limit your data import and analyses to the extent of the counties Otter Tail, Douglas, Grant, Todd and Wadena.\nFor this tutorial, the assumption is that you copy all required input files to the working directory. On the command line, use the cd command to set the working directory. In Python, you can change the working directory using the os.chdir command.\n\n1.5.1 Boundaries\nFirst, download the vector layer with the Minnesota counties as a GeoPackage from here. Copy the data to your working directory, and import the layer in GRASS GIS.\n\n\n\n\nYou can import the entire layer using v.in.ogr, and next, select the required subset using the v.extract function.\n# Import\nv.in.ogr input=bdry_counties_in_minnesota.gpkg \\\nlayer=mn_county_boundaries output=Minnesota_counties\n\n# Select\nv.extract input=Minnesota_counties \nwhere=\"CTY_NAME = 'Otter Tail' OR CTY_NAME = 'Douglas' OR  CTY_NAME = 'Grant' OR CTY_NAME = 'Todd' OR  CTY_NAME = 'Wadena'\" output=study_area\nAlternatively, you can limit your import to those counties you are interested in directly using the where parameter.\nv.in.ogr input=bdry_counties_in_minnesota.gpkg \\\nlayer=mn_county_boundaries output=Minnesota_counties \\\nwhere=\"CTY_NAME = 'Otter Tail' OR CTY_NAME = 'Douglas' OR  CTY_NAME = 'Grant' OR CTY_NAME = 'Todd' OR  CTY_NAME = 'Wadena'\"\n\n\nYou can import the whole layer using v.in.ogr, and next, select the required subset using the v.extract function.\n# Import\ngs.run_command(\n    \"v.in.ogr\",\n    input=\"bdry_counties_in_minnesota.gpkg\",\n    layer=\"mn_county_boundaries\",\n    output=\"Minnesota_counties\",\n)\n\n# Select subset\ngs.run_command(\n    \"v.extract\",\n    input=\"Minnesota_counties\",\n    where=(\n        \"CTY_NAME = 'Otter Tail' OR \"\n        \"CTY_NAME = 'Douglas' OR \"\n        \"CTY_NAME = 'Grant' OR \"\n        \"CTY_NAME = 'Todd' OR  \"\n        \"CTY_NAME = 'Wadena'\"\n    ),\n    output=\"study_area\",\n)\nAlternatively, you can limit your import to those counties you are interested in directly using the where parameter.\n# Import\ngs.run_command(\n    \"v.in.ogr\",\n    input=\"bdry_counties_in_minnesota.gpkg\",\n    layer=\"mn_county_boundaries\",\n    where=(\"CTY_NAME = 'Otter Tail' OR \"\n           \"CTY_NAME = 'Douglas' OR  \"\n           \"CTY_NAME = 'Grant' OR \"\n           \"CTY_NAME = 'Todd' OR  \"\n           \"CTY_NAME = 'Wadena'\"),\n    output=\"study_area2\",\n)\n\n\n\nNow, use the g.region function to set the regional extent to match the extent of the selected counties.\n\n\n\n\ng.region vector=study_area\n\n\ngs.run_command(\"g.region\", vector=\"study_area\")\n\n\n\n\n\n1.5.2 Land cover\nOne of the main data layers you are going to work with is the National Land Cover Database (NLCD) of the USA. You can download the NLCD layer for Minnesota from the Minnesota GIS portal. There are :various versions. The examples in this tutorial are based on the NLCD for 2016, which you can download here as a geoTIF raster layer.\nNext, use the functions r.in.gdal to import the raster data in GRASS GIS. Set the -r flag to limit the import to the computational region. Note that because r.in.gdal does not change the resolution and alignment of the original layer, the extent of the imported layer may be slightly larger than the regional extent.\n\n\n\n\n# Import land use map\nr.in.gdal -r input=NLCD_2016_Land_Cover.tif output=NLCD_2016_30m\n\n\n# Import land use map\ngs.run_command(\n    \"r.in.gdal\",\n    flags=\"r\",\n    input=\"NLCD_2016_Land_Cover.tif\",\n    output=\"NLCD_2016_30m\",\n)\n\n\n\nAnother way to reduce the computation time is to work with a lower resolution. Use the g.region function again, and this time use the res parameter to set the resolution to 60 meters. Use the -a flag to align region to resolution (this ensures the resolution will be exactly as requested).\n\n\n\n\ng.region -a -p res=60 raster=NLCD_2016\n\n\ngs.run_command(\"g.region\", flags=\"ap\", res=60, raster=\"NLCD_2016\")\n\n\n\nAll raster calculations in GRASS GIS use the resolution as defined with the computation region. If the resolution of an input raster differs from the resolution of the computational region, GRASS GIS will resample the input raster to the cell resolution of the computational region ‘on-the-fly’ while carrying out raster calculations. By default, it will use the :nearest neighbor method\nFor categorical maps such as the NLCD_2016 raster layer, it is usually more appropriate to use the mode of the input cells that intersect the output cell. Therefore, use the r.resample.stats function to resample the NLCD layer to the desired resolution. Set the method to mode. Optionally, you can set the -w flag. With this option, the values from each input cell is weighted according to how much the input cell overlaps with the output cell. This is slower, but produces a more accurate result.\n\n\n\n\nr.resamp.stats -w input=NLCD_2016_30m output=NLCD_2016 method=mode\n\n\ngs.run_command(\n    \"r.resamp.stats\",\n    flags=\"w\",\n    input=\"NLCD_2016_30m\",\n    output=\"NLCD_2016\",\n    method=\"mode\",\n)\n\n\n\n\n\n1.5.3 Infrastructure\nYou will also need a dataset of the infrastructure and buildings of Minnesota. For this tutorial, you’ll use the Openstreetmap data. Geofrabric offers a convenient free download server where you can download OSM data for the individual USA states.\nDownload the zip file with Shapefiles for Minnesota and unzip the layers in your working directory. The zip files include various Shapefiles. Import the layers gis_osm_buildings_a_free_1, gis_osm_railways_a_free_1, gis_osm_roads_a_free_1 and gis_osm_traffic_a_free_1. The data is in latlon (EPSG 4326) so you need to use the r.import function. This will reproject your data on-the-fly during import. Use the extent parameter to limit the import to the current computational region.\n\n\n\n\nv.import input=gis_osm_buildings_a_free_1.shp output=buildings extent=region\nv.import input=gis_osm_railways_free_1.shp output=railways extent=region\nv.import input=gis_osm_roads_free_1.shp output=railways extent=region\nv.import input=gis_osm_traffic_a_free_1.shp output=railways extent=region\n\n\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_buildings_a_free_1.shp\",\n    output=\"buildings\",\n    extent=\"region\",\n)\n\ngs.run_command(\n    \"v.import\", input=\"gis_osm_railways_free_1.shp\", output=\"railways\", extent=\"region\"\n)\n\ngs.run_command(\n    \"v.import\", input=\"gis_osm_roads_free_1.shp\", output=\"roads\", extent=\"region\"\n)\n\ngs.run_command(\n    \"v.import\", input=\"gis_osm_traffic_a_free_1.shp\", output=\"traffic\", extent=\"region\"\n)\n\n\n\nIn the next sections, you will map the (suitability) distribution of the White tailed deer. If you have prepared the data following the steps in this section, you will do this for an area covering the counties Otter Tail, Douglas, Grant, Todd and Wadena, at a resolution of 60 meter. If you have prepared your data according to the steps in Section 1.4, you will create a suitability map for the state of Minnesota, at a resolution of 30m.\n\n:x varversions\nLike the 2019 version, which you can download here. If you want to use that layer, you probably also want to get the more recent numbers for deer densities as well (see Section 2.1).\n\n\n:x mode\nThe mode, also called majority resampling, is the most frequently occurring value of the input cells that intersect the output cell. Read more about this and alternative resampling techniques here.\n\n\n:x nearestneighbor\nThe nearest neighbor technique doesn’t change any of the values from the input raster data set. It takes the cell center from the input raster data set to determine the closest cell center of the output raster. For processing speed, it’s generally the fastest because of its simplicity. Read more about this and alternative resampling techniques here.\n\n\n\n\n\n\n\n\n\n\n\n\n1. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "2_deerdensities.html",
    "href": "2_deerdensities.html",
    "title": "2  Deer densities",
    "section": "",
    "text": "2.1 Get the data\nFor this tutorial, you’ll be using deer density estimates for Minnesota for the years 2010-20171. The densities are provided per deer permit area (DPA). These are areas with similar habitat, land uses, deer populations, and deer hunter distribution.\nThe first step is to extract the table with the deer densities from the PDF file and reformat it to get a table with one column with the PDA id’s and the other columns with the deer densities for the different years. In addition, we are working with the metric system, so we need to convert the numbers from deer/mi\\(^2\\) need to deer/km\\(^2\\).\nTo save you the trouble, I have already done this for you. You can download the zip file with the CSV file DPA_deer_densities.csv and the accompanying DPA_deer_densities.csvt file. The latter is to ensure the columns of the CSV file are imported with the proper type (see here for more information). Unzip both files in your working directory.\nThe table gives the density estimates per PDA, so you’ll need a map with the DPA boundaries to map the deer densities. On the Minnesota Geospatial commons website, only the latest DPA boundaries can be downloaded (as far as I can tell). I therefore used the DPA map of 2021 and adapted it to approximate the 2017 boundaries. Download the map and copy it to your working directory. The map I based this on is, unfortunately, not available anymore, so you’ll have to take my word for it.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Deer densities</span>"
    ]
  },
  {
    "objectID": "2_deerdensities.html#spatial-join",
    "href": "2_deerdensities.html#spatial-join",
    "title": "2  Deer densities",
    "section": "2.2 Spatial join",
    "text": "2.2 Spatial join\nAfter downloading the DPA map and the table with deer densities, import both in GRASS GIS, and join the table with deer densities to the attribute table of the DPA vector layer, based on the DPA ID’s in both tables (Figure 2.1). We’ll use the functions v.in.ogr, db.in.ogr and v.db.join.\n\n\n\n\n# Import the vector layer\nv.in.ogr  input=DPA_boundaries.gpkg output=deer_densities\n\n# Import the csv file\ndb.in.ogr input=DPA_deer_densities.csv output=deerdensities\n\n# Join table to vector layer\nv.db.join map=deer_densities column=DPA \\\nother_table=deerdensities other_column=DPA \\\nsubset_columns=density2017\n\n\n# Import the vector layer\ngs.run_command(\"v.in.ogr\", input=\"DPA_boundaries.gpkg\", output=\"deer_densities\")\n\n# Import the csv file\ngs.run_command(\n    \"db.in.ogr\", input=r\"DPA_deer_densities.csv\", output=\"deerdensities\"\n)\n\n# Join table to vector layer\ngs.run_command(\n    \"v.db.join\",\n    map=\"deer_densities\",\n    column=\"DPA\",\n    other_table=\"deerdensities\",\n    other_column=\"DPA\",\n    subset_columns=\"density2017\",\n)\n\n\n\nNow, convert the vector layer to a raster layer representing the deer_densities in 2017. You can use the function v.to.rast to rasterize the vector layer. Use the estimated deer densities for 2017 as raster values. The where parameter serves to ensure that polygons without values are converted to no-data raster cells instead of getting a value of zero.\n\n\n\n\nv.to.rast input=deer_densities use=attr attribute_column=density2017 \\\noutput=deer_tmp where=\"density2017 != ''\"\n\n\ngs.run_command(\n    \"v.to.rast\",\n    input=\"deer_densities\",\n    use=\"attr\",\n    attribute_column=\"density2017\",\n    output=\"deer_tmp\",\n    where=\"density2017 != ''\",\n)\n\n\n\nFor some DPA’s there were no estimates, leaving gaps in the map. To fill those gaps, you can use nearest neighbor interpolation (Thiessen polygons). This will assign values to the empty raster cells that are equal to the nearest neighboring raster cell with a value. You can use the r.grow.distance function to do this by providing the name for the value output raster map using the value.\n\n\n\n\nr.grow.distance input=deer_tmp value=deer_densities\n\n\ngs.run_command(\"r.grow.distance\", input=\"deer_tmp\", value=\"deer_densities\")\n\n\n\nThe resulting layer deer_densities gives the deer densities (deer/km\\(^2\\)) per DPA. Nice, but deer densities will not be uniformly distributed across the DPA’s. In general, one may expect deer densities to be higher in areas with more resources (food and shelter). So, to account for such differences in resource availability within the DPA’s, you will create a potential suitability distribution map (section 3). Assuming that deer densities are proportional to the suitability index score, use the habitat suitability map to disaggregate the deer density numbers (section 4).\nAs a final step, remove all intermediate layers.\n\n\n\n\ng.remove -f type=raster name=deer_tmp\n\n\ngs.run_command(\"g.remove\", flags=\"f\", type=\"raster\", name=\"deer_tmp\")\n\n\n\n\n\n\n\n\n\n\n\n1. Norton A, Giudice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2017.; 2017:13. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2017.pdf\n\n\n2. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Deer densities</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html",
    "href": "3_habitatsuitability.html",
    "title": "3  Habitat suitability",
    "section": "",
    "text": "3.1 Introduction\nQuality deer habitats include a mixture of different habitats. Some are particularly important for food, while others are important for shelter. This tutorial follows the method by Fleming et al.1 to compute the white-tailed deer habitat suitability index. This method assigns scores to the different land cover categories of the National Land Cover Dataset (NLCD)2, reflecting their quality in terms of food (QHF) and shelter (QHS) availability.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html#introduction",
    "href": "3_habitatsuitability.html#introduction",
    "title": "3  Habitat suitability",
    "section": "",
    "text": "Figure 3.1: From the land cover map to habitat suitability map in three steps: Reclassification of land cover types to suitability scores based on shelter and food availability, moving window inverse distance averaging of suitability scores, and the combination of the QHF and QHS maps based on the minimum score. If you are not familiar with moving window statistics (also called focal raster statistics), see this video tutorial.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html#sec-relassification",
    "href": "3_habitatsuitability.html#sec-relassification",
    "title": "3  Habitat suitability",
    "section": "3.2 Reclassification",
    "text": "3.2 Reclassification\nYou’ll use the r.recode.attr addon to reclassify the NLCD land cover data into two new raster layers; one reflecting the relative habitat suitability based on available food (QHF) and the other reflecting the relative habitat suitability based on available shelter (QHS). You can install the addon through the graphical user interface (Menu → Settings → Addons Extension → Install) or via the g.extension command.\n\n\n\n\ng.extension extension=r.recode.attr\n\n\ngs.run_command(\"g.extension\", extension=\"r.recode.attr\")\n\n\n\nBesides the NLCD raster layer, the r.recode.attr function requires a conversion table with in the first column the ID’s of the land cover categories, and in the second and third columns the corresponding suitability scores based on food and shelter availability Table 3.1. Note that the land cover category 11 (water) is not included in the conversion table. The corresponding cells in the output raster layers will have NODATA values. This is done because water should be ignored in the next step (paragraph 3.3).\n\n\n\n\nTable 3.1: Converion table with for each land cover category (LCID) the corresponding suitability scores based on the assumed relative food and shelter availability within those land cover categories. The values in the table are based on Fleming et al.1, with some modifications.\n\n\n\n\n\n\n\n\n\n\nDownload the CSV file deerSHI.csv by pushing the CSV button above and copy the file to your working directory and run the code below. Note that if you want to use different conversion values, first change those values in Table 3.1 by double-clicking the cell you would like to edit.\n\n\n\n\nr.recode.attr input=NLCD_2016 output=DHSI rules=deerSHI.csv\n\n\ngs.run_command(\"r.recode.attr\", input=\"NLCD_2016\",\n               output=\"DHSI\", rules=\"deerSHI.csv\")\n\n\n\nIf you are not able or want to install the r.recode.attr addon, you can also use the r.recode function. You’ll need the files containing the recode rules, DHSI_food.csv and DHSI_shelter.csv, as input. Running the code below will yield the same results as the code above.\n\n\n\n\nr.recode -d input=NLCD_2016 output=DHSI_food rules=DHSI_food.csv\nr.recode -d input=NLCD_2016 output=DHSI_shelter rules=DHSI_shelter.csv\n\n\ngs.run_command(\n    \"r.recode\", flags=\"d\", input=\"NLCD_2016\", output=\"DHSI_food\",\n    rules=\"DHSI_food.csv\"\n)\ngs.run_command(\n    \"r.recode\", input=\"NLCD_2016\", output=\"DHSI_shelter\",\n    rules=\"DHSI_shelter.csv\"\n)    \n\n\n\nThe resulting layers are DHSI_shelter and DHSI_food. These will serve as input for the next step.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html#sec-movingwindow",
    "href": "3_habitatsuitability.html#sec-movingwindow",
    "title": "3  Habitat suitability",
    "section": "3.3 Moving window average",
    "text": "3.3 Moving window average\nThe next step is based on the assumption that the suitability of a site is not only determined by the food and shelter available at that site, but also by the availability of food and shelter in the immediate vicinity1. The exception is water; the presence of water is assumed to have no influence on the suitability of its surroundings, and vice versa.\nTo account for the availability of food around a grid cell, you’ll calculate the inverse distance-weighted average QHF score of the cells within 450 meters of that cell. That is, for each cell, the average value of all cells within 450 meters is calculated, with cells further away contributing less to the average score than cells closer by. Similarly, to account for shelter availability in the surroundings, you’ll compute the inverse distance-weighted average QHS scores of the cells within 210-meter distance.\nTo calculate an inverse distance weighted average (IDWA), you’ll use the r.mfilter function. As input, it uses a matrix weight filter file. Assuming the resolution you’re working with is 30 meters, you can use the matrix filter files QHFwaf_30m.txt and QHSwaf_30m.txt to calculate the IDWA of QHF and QHS respectively. Download these files into your working directory. :Click here to see what to do when working at a different resolution.\n\n\n\n\n# Remove the mask\n1r.mask -r\n\n# Compute the focal statistics\nr.mfilter  input=DHSItempS output=DHSI_shelterS, \\\n2filter=QHSwaf_30m.txt nprocs=4\n\nr.mfilter input=DHSItempF output=DHSI_foodS \\\nfilter=QHFwaf_30m.txt nprocs=4\n\n1\n\nParallel processing can speed up the computation of r.mfilter considerably. However, when a MASK is set, parallel processing is disabled. So, make sure to remove the MASK first.\n\n2\n\nWith nprocs you set the number of threads for parallel computing. Change the number to fit your system.\n\n\n\n\n# Remove the mask\n1gs.run_command(\"r.mask\", flags=\"r\")\n\n# Compute the focal statistics\ngs.run_command(\n    \"r.mfilter\",\n    input=\"DHSI_shelter\",\n    output=\"DHSI_shelterS\",\n    filter=\"QHSwaf_30m.txt\",\n2    nprocs=4,\n)\ngs.run_command(\n    \"r.mfilter\",\n    input=\"DHSI_food\",\n    output=\"DHSI_foodS\",\n    filter=\"QHFwaf_30m.txt\",\n    nprocs=4, \n)\n\n1\n\nParallel processing can speed up the computation of r.mfilter considerably. However, when a MASK is set, parallel processing is disabled. So, make sure to remove the MASK first.\n\n2\n\nWith nprocs you set the number of threads for parallel computing. Change the number to fit your system.\n\n\n\n\n\nRemember that in paragraph 3.2, areas classified as water in the NLCD raster layer were assigned a null value in the DHSI_shelter and DHSI_food raster layers. Because null cells are ignored by r.mfilter, the presence of water has no influence on the suitability of its surroundings, and vice versa. This meets the second assumption mentioned at the beginning of this section.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html#habitat-suitability-index",
    "href": "3_habitatsuitability.html#habitat-suitability-index",
    "title": "3  Habitat suitability",
    "section": "3.4 Habitat suitability index",
    "text": "3.4 Habitat suitability index\nTo create the final deer habitat suitability index (DHSI), use the r.series function to calculate the minimum of QHF and QHF scores applied to each pixel in the landscape.\n\n\n\n\n# Combine the layers\nr.series input=DHSI_shelterS,DHSI_foodS, \\\n1output=HSI_tmp, method=minimum nprocs=4\n\n1\n\nWith nprocs you set the number of threads for parallel computing. Change the number to fit your system.\n\n\n\n\n# Combine the layers\ngs.run_command(\n    \"r.series\",\n    input=[\"DHSI_shelterS\", \"DHSI_foodS\"],\n    output=\"HSI_tmp\",\n    method=\"minimum\",\n1    nprocs=4\n)\n\n1\n\nWith nprocs you set the number of threads for parallel computing. Change the number to fit your system.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html#infrastructure-water",
    "href": "3_habitatsuitability.html#infrastructure-water",
    "title": "3  Habitat suitability",
    "section": "3.5 Infrastructure & water",
    "text": "3.5 Infrastructure & water\nIn the raster layer created in the previous sections, roads, buildings, and other built-up areas may have gotten a score &gt; 0, depending on their surroundings. To ensure that all build-up areas have a suitability score of 0, convert the various infrastructure vector layers you imported earlier (Section 1.4.3 or 1.5.3) to raster layers using the v.to.rast function. Use the use and value parameters to assign the value 0 to the various features in the resulting raster layers. The -d flag is to densify line features (see the manual page for details).\n\n\n\n\nv.to.rast input=buildings output=buildings \\\n1use=val value=0 memory=1000\n\nv.to.rast input=railways output=railways \\\nuse=val value=0 memory=1000  \n\nv.to.rast input=roads output=roads \\\nuse=val value=0 memory=1000  \n\nv.to.rast input=traffic output=traffic \\\nuse=val value=0 memory=1000  \n\n1\n\nIncreasing the memory (in MB) to be used will speed up your calculations. Change this according to your system’s memory. If you don’t know, see here how to check your system’s memory.\n\n\n\n\ngs.run_command(\n    \"v.to.rast\",\n    input=\"buildings\",\n    output=\"buildings\",\n    use=\"val\",\n    value=0,\n1    memory=1000,\n)\ngs.run_command(\n    \"v.to.rast\",\n    flags=\"d\",\n    input=\"railways\",\n    output=\"railways\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\ngs.run_command(\n    \"v.to.rast\",\n    flags=\"d\",\n    input=\"roads\",\n    output=\"roads\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\ngs.run_command(\n    \"v.to.rast\",\n    input=\"traffic\",\n    output=\"traffic\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\n\n1\n\nIncreasing the memory (in MB) to be used will speed up your calculations. Change this according to your system’s memory. If you don’t know, see here how to check your system’s memory.\n\n\n\n\n\nThe next step is to combine the various raster layers you created in the previous step with the HSI_tmp using the r.patch function. This function will take the values of the first raster layer in the provided list (buildup), and if that layer has “no data” cells, the values of the second raster layer (HSI_temp) are used for these cells.\n\n\n\n\nr.patch input=buildings,railways,roads,traffic,HSI_tmp \\\noutput=HSI_tmp2 \\\n1memory=1000 \\\n2nprocs=4\n\n1\n\nIncreasing the memory (in MB) to be used will speed up your calculations. Change this according to your system’s memory. If you don’t know, see here how to check your system’s memory.\n\n2\n\nWith nprocs you set the number of threads for parallel computing. Change the number to fit your system.\n\n\n\n\ngs.run_command(\n    \"r.patch\",\n    input=[\n        \"buildings\",\n        \"railways\",\n        \"roads\",\n        \"traffic\",\n        \"HSI_tmp\",\n    ],\n    output=\"HSI_tmp2\",\n1    memory=1000,\n2    nprocs=4,\n)\n\n1\n\nIncreasing the memory (in MB) to be used will speed up your calculations. Change this according to your system’s memory. If you don’t know, see here how to check your system’s memory.\n\n2\n\nWith nprocs you set the number of threads for parallel computing. Change the number to fit your system.\n\n\n\n\n\n\nAnd, to get the final habitat suitability layer for the White-tailed deer, assign the value 0 to all areas with water, and no data to all areas outside the boundaries of the state.\n\n\n\n\nr.mask vector=Minnesota_bdry\nr.mapcalc expression=\"HSI_deer = if(NLCD_2016==11,0,HSI_tmp2)\"\n\n\ngs.run_command(\"r.mask\", vector=\"Minnesota_bdry\")\ngs.run_command(\"r.mapcalc\", expression=\"HSI_deer = if(NLCD_2016==11,0,HSI_tmp2)\")\n\n\n\nAs a final step, remove all intermediate layers.\n\n\n\n\ng.remove -f type=vector,raster \\\nname=buildings,railways,roads,traffic,HSI_tmp,HSI_tmp2, DHSI_shelter,DHSI_food,DHSI_foodS,DHSI_shelterS,deer_tmp\n\n\ngs.run_command(\n    \"g.remove\",\n    flags=\"f\",\n    type=\"raster\",\n    name=[\n        \"buildings\",\n        \"railways\",\n        \"roads\",\n        \"traffic\",\n        \"HSI_tmp\",\n        \"HSI_tmp2\",\n        \"DHSI_shelter\",\n        \"DHSI_food\",\n        \"DHSI_foodS\",\n        \"DHSI_shelterS\",\n        \"deer_tmp\",\n    ],\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "3_habitatsuitability.html#climate",
    "href": "3_habitatsuitability.html#climate",
    "title": "3  Habitat suitability",
    "section": "3.6 Climate",
    "text": "3.6 Climate\nThere are other factors that influence the suitability of an area for white-tailed deer. One of these is climate, and more specifically, the winter severity, which determines the northernmost limit of the species distribution3. In general, the species is well adapted to survive Minnesota’s cold, snowy winters. However, severe winters, which occur every so many years in the north of the state, can increase deer mortality, thus influencing population densities4.\nWe did not take winter severity, nor other potentially important factors such as hunting, into account, as this can differ from year to year. In addition, these factors are already considered in the density estimates per deer permit area (DPA) dataset that we used to create the deer density distribution map (Chapter 2).\n\n:x invisible1\nIf you run the analysis with a 60-meter resolution, use the matrix weight files QHFwaf_60m.txt and QHSwaf_60m.txt instead. For any other resolution, you need to create the appropriate matrix weight files yourself. You can do this using the Python script compute rmfilter.py.\n\n\n\n\n\n\n\n\n\n\n\n1. Fleming KK, Didier KA, Miranda BR, Porter WF. Sensitivity of a white-tailed deer habitat-suitability index model to error in satellite land-cover data: Implications for wildlife habitat-suitability studies. Wildlife Society Bulletin. 2004;32(1):158-168. doi:10.2193/0091-7648(2004)32[158:SOAWDH]2.0.CO;2\n\n\n2. MRLC. CONUS land cover, national land cover database (NLCD) 2016. Published online 2016. https://www.mrlc.gov/.\n\n\n3. Kennedy-Slaney L, Bowman J, Walpole AA, Pond BA. Northward bound: The distribution of white-tailed deer in ontario under a changing climate. Wildlife Research. 2018;45(3):220-228. doi:10.1071/WR17106\n\n\n4. MNDNR. How winter impacts deer survival. Published online 2021. https://www.dnr.state.mn.us/mammals/deer/management/wsi.html\n\n\n5. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Habitat suitability</span>"
    ]
  },
  {
    "objectID": "4_spatialdisaggregation.html",
    "href": "4_spatialdisaggregation.html",
    "title": "4  Spatial disaggregation",
    "section": "",
    "text": "In Chapter 2 you created a map showing deer densities per deer permit area (DPA). However, deer densities will not be uniformly distributed across the DPA’s. In general, one may expect deer densities to be higher in areas with more resources (food and shelter). To account for such differences in resource availability within the DPA’s, assume that deer densities are proportional to the suitability index score.\n\n\n\n\n\n\nFigure 4.1: Spatial allocation of deer densities, proportionally to the HSI scores\n\n\n\nTo accomplish this, you’ll calculate for each of the 130 deer permit areas (DPA) the relative habitat suitability of each raster cell as the ratio between the HSI of that cell divided by the average HSI of the whole DPA. Next, you’ll multiply this with the deer density of the DPA.\n\\(DD_{i} = \\frac{HSI_{i}}{\\overline{HSI}_j} \\times DD_{j}\\)\nWith \\(DD_{i}\\) as the deer density of cell i, \\(HSI_{i}\\) the habitat suitability score in cell i, \\(\\overline{HSI}_{j}\\) the average habitat suitability scores in the DPA j, and \\(DD_{j}\\) the deer density of DPA j.\nThe first step is to create a raster layer of the DPA’s. Remember that the vector layer deer_densities that you imported earlier is, in fact, a map of the DPA’s, with per DPA the deer densities per DPA. So we can simply convert this vector layer to a raster layer again, but this time using the column DPA as the source for the raster value.\n\n\n\n\nv.to.rast input=deer_densities use=attr \\\nattribute_column=DPA output=dpa\n\n\n# Create base map with with DPA as zones\ngs.run_command(\n    \"v.to.rast\",\n    input=\"deer_densities\",\n    use=\"attr\",\n    attribute_column=\"DPA\",\n    output=\"dpa\",\n)\n\n\n\nNext, use r.stats.zonal to calculate the average suitability scores per DPA.\n\n\n\n\n# Compute sum/average HSI score per DPA\nr.stats.zonal base=dpa cover=HSI_deer \\\nmethod=average output=HSI_average\n\n\n# Compute sum/average HSI score per DPA\ngs.run_command(\n    \"r.stats.zonal\",\n    base=\"dpa\",\n    cover=\"HSI_deer\",\n    method=\"average\",\n    output=\"HSI_average\",\n)\n\n\n\nAnd as a final step, use the versatile r.mapcalc to calculate the relative density.\n\n\n\n\n# Calculate the relative density\nr.mapcalc expression=\"DeerDensities = (HSI_deer/HSI_average)*deer_densities\"\n\n\n# Calculate the relative density\ngs.run_command(\n    \"r.mapcalc\",\n    expression=(\"DeerDensities = (HSI_deer/HSI_average)*deer_densities\"),\n)\n\n\n\nIf you plot the resulting map, you’ll see that there are some small areas with very high density estimates, up to 96 deer/km\\(^2\\). Apart from the question of how credible these numbers are, these outliers make it difficult to discern any clear pattern in deer densities in the rest of the state. We could use a logarithmic or histogram equalization scale for the color legend. However, that doesn’t make it necessarily easier to interpret the resulting map.\nAs an alternative, we can remove the 2% highest values. We can do this by rescaling all values that are larger than the 98 percentile to be equal to the 98 percentile. First, find out the value of the 98st percentile. You can use the function r.quantile to do this.\n\n\n\n\nr.quantile input=\"DeerDensities percentiles=98\n\n\nNote that you use the gs.read_command instead of the gs.run_command you used before. Read more about the differences between these functions in the GRASS Python scripting manual.\ngs.read_command(\n    \"r.quantile\",\n    input=\"DeerDensities\",\n    percentiles=98,\n)\n\n\n\nYou’ll find that the outcome is 24.8. That means that you need to reclassify all raster cells with deer densities higher than 24.8 to 24.8. All other cells retain their original value. You can do this with r.mapcalc.\n\n\n\n\nr.mapcalc expression=\"Deer_Densities = if(DeerDensities &gt; 24.8, 24.8, DeerDensities)\" -overwrite\n\n\ngs.run_command(\n    \"r.mapcalc\",\n    expression=\"DeerDensities = if(DeerDensities &gt; 24.8, 24.8, DeerDensities)\",\n    overwrite=True,\n)\n\n\n\nAs a final step, remove all intermediate layers.\n\n\n\n\ng.remove -f type=raster,vector name=deer_densities,deer_tmp,dpa,HSI_average\n\n\ngs.run_command(\n    \"g.remove\",\n    flags=\"f\",\n    type=[\"raster\", \"vector\"],\n    name=[\n        \"deer_densities\",\n        \"deer_tmp\",\n        \"dpa\",\n        \"HSI_average\",\n    ],\n)\n\n\n\n\n\n\n\n\n\n\n\n1. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Spatial disaggregation</span>"
    ]
  },
  {
    "objectID": "5_results.html",
    "href": "5_results.html",
    "title": "5  Results",
    "section": "",
    "text": "During our exercise, we made several assumptions about the habitat suitability and how this affects the distribution of the white-tailed deer. And we ignored other potentially important factors, such as hunting and the effects of predators. Some factors, such as winter conditions, were included in the estimates of deer densities per DPA from Norton and Giudice1. But that means we made the implicit assumption that those factors have a uniform influence on deer densities across the DPA.\n\n\n\n\n\n\nFigure 5.1: Map with estimated relative deer population densities.\n\n\n\nIn real life, you will often have to make many assumptions as well. That’s what makes it essential to document all your steps, including the assumptions made. The great thing about GRASS GIS is that it is so easy to provide the code, making the analysis more transparent, unambiguous, and reproducible. And because all steps are automated, it is relatively easy to test how sensitive the outcome is to small changes in the parameters or data (sensitivity analysis). You can do this yourself; just make some changes in the code and see how or where that changes the outcome and to what extent.\n\n\n\n\n1. Norton A, Giudice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2017.; 2017:13. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2017.pdf\n\n\n2. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "1. Fleming KK, Didier KA, Miranda BR, Porter WF.\nSensitivity of a white-tailed deer habitat-suitability index model to\nerror in satellite land-cover data: Implications for wildlife\nhabitat-suitability studies. Wildlife Society Bulletin.\n2004;32(1):158-168. doi:10.2193/0091-7648(2004)32[158:SOAWDH]2.0.CO;2\n\n\n2. MRLC. CONUS land cover, national land cover\ndatabase (NLCD) 2016. Published online 2016. https://www.mrlc.gov/.\n\n\n3. Kennedy-Slaney L, Bowman J, Walpole AA, Pond\nBA. Northward bound: The distribution of white-tailed deer in ontario\nunder a changing climate. Wildlife Research.\n2018;45(3):220-228. doi:10.1071/WR17106\n\n\n4. MNDNR. How winter impacts deer survival.\nPublished online 2021. https://www.dnr.state.mn.us/mammals/deer/management/wsi.html\n\n\n5. Norton A, Giudice JH. Monitoring Population\nTrends of White-Tailed Deer in Minnesota - 2017.; 2017:13. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2017.pdf\n\n\n6. Michiel ES, Guidice JH. Monitoring\nPopulation Trends of White-Tailed Deer in Minnesota - 2022.\nMinnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "all_code.html",
    "href": "all_code.html",
    "title": "Appendix A. All code",
    "section": "",
    "text": "2: Getting started",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>All code</span>"
    ]
  },
  {
    "objectID": "all_code.html#getting-started",
    "href": "all_code.html#getting-started",
    "title": "Appendix A. All code",
    "section": "",
    "text": "# Import libraries\nimport grass.script as gs\nimport os\n\n# Set working directory\nos.chdir(\"path_to_working_directory\")\n\n# Fill in\nlocation = \"Minnesota\"\nmapset = \"WhitetailedDeer2\"\n\n# Create location and mapset\ngs.run_command(\"g.mapset\", flags=\"c\", location=location, mapset=mapset)\n\n# Import vector layer with Minnesota boundary\ngs.run_command(\n    \"v.in.ogr\",\n    input=\"bdry_state_of_minnesota.gpkg\",\n    layer=\"state_of_minnesota\",\n    output=\"Minnesota_bdry\",\n)\n\n# Set the region to match the extent of Minnesota\ngs.run_command(\"g.region\", vector=\"Minnesota_bdry\")\n\n# Import land use map. Use the -r flag to limit the import to the region's extent\ngs.run_command(\n    \"r.in.gdal\",\n    flags=\"r\",\n    input=\"NLCD_2016_Land_Cover.tif\",\n    output=\"NLCD_2016\",\n    memory=1000,\n)\n\n# set the region to match extent and resolution of NLCD_2016\ngs.run_command(\n    \"g.region\",\n    flags=\"a\",\n    raster=\"NLCD_2016\",\n)\n\n# Import building feature layer and convert to raster\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_buildings_a_free_1.shp\",\n    output=\"buildings\",\n)\ngs.run_command(\n    \"v.to.rast\",\n    input=\"buildings\",\n    output=\"buildings\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\ngs.run_command(\"g.remove\", flags=\"f\", type=\"vector\", name=\"buildings\")\n\n# Import railway feature layer and convert to raster\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_railways_free_1.shp\",\n    output=\"railways\",\n)\ngs.run_command(\n    \"v.to.rast\",\n    flags=\"d\",\n    input=\"railways\",\n    output=\"railways\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\ngs.run_command(\"g.remove\", flags=\"f\", type=\"vector\", name=\"railways\")\n\n# Import roads feature layer and convert to raster\ngs.run_command(\n    \"v.import\",\n    input=\"gis_osm_roads_free_1.shp\",\n    output=\"roads\",\n)\ngs.run_command(\n    \"v.to.rast\",\n    flags=\"d\",\n    input=\"roads\",\n    output=\"roads\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\ngs.run_command(\"g.remove\", flags=\"f\", type=\"vector\", name=\"roads\")\n\n# Import traffic feature layer and convert to raster\ngs.run_command(\"v.import\", input=\"gis_osm_traffic_a_free_1.shp\", output=\"traffic\")\ngs.run_command(\n    \"v.to.rast\",\n    input=\"traffic\",\n    output=\"traffic\",\n    use=\"val\",\n    value=0,\n    memory=1000,\n)\ngs.run_command(\"g.remove\", flags=\"f\", type=\"vector\", name=\"traffic\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>All code</span>"
    ]
  },
  {
    "objectID": "all_code.html#deer-densities",
    "href": "all_code.html#deer-densities",
    "title": "Appendix A. All code",
    "section": "3: Deer densities",
    "text": "3: Deer densities\n# Import the DPA vector layer\ngs.run_command(\"v.in.ogr\", input=\"DPA_boundaries.gpkg\", output=\"deer_densities\")\n\n# Import the csv file with deer density numbers\ngs.run_command(\n    \"db.in.ogr\",\n    input=r\"DPA_deer_densities.csv\",\n    output=\"deerdensities\",\n)\n\n# Join table to vector layer\ngs.run_command(\n    \"v.db.join\",\n    map=\"deer_densities\",\n    column=\"DPA\",\n    other_table=\"deerdensities\",\n    other_column=\"DPA\",\n    subset_columns=\"density2017\",\n)\n\n# Convert the deer density vector layer to raster layer\ngs.run_command(\n    \"v.to.rast\",\n    input=\"deer_densities\",\n    use=\"attr\",\n    attribute_column=\"density2017\",\n    output=\"deer_tmp\",\n    where=\"density2017 != ''\",\n)\n\n# Use nearest neighbor interpolation to fill in gaps\ngs.run_command(\n    \"r.grow.distance\", input=\"deer_tmp\", value=\"deer_densities\", overwrite=True\n)\n\n# Clean up\ngs.run_command(\"g.remove\", flags=\"f\", type=\"raster\", name=\"deer_tmp\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>All code</span>"
    ]
  },
  {
    "objectID": "all_code.html#habitat-suitability",
    "href": "all_code.html#habitat-suitability",
    "title": "Appendix A. All code",
    "section": "4: Habitat suitability",
    "text": "4: Habitat suitability\n# Install r.recode.attr extension\ngs.run_command(\"g.extension\", extension=\"r.recode.attr\")\n\n# Recode NLCD layer to create DHSI_shelter and _food layers\ngs.run_command(\"r.recode.attr\", input=\"NLCD_2016\", output=\"DHSI\", rules=\"deerSHI.csv\")\n\n# remove mask (just in case there is one)\ntry:\n    gs.run_command(\"r.mask\", flags=\"r\")\nexcept:\n    pass\n\n# Moving window average of both DHSI layers\ngs.run_command(\n    \"r.mfilter\",\n    input=\"DHSI_shelter\",\n    output=\"DHSI_shelterS\",\n    filter=\"QHSwaf_30m.txt\",\n    nprocs=4,\n)\ngs.run_command(\n    \"r.mfilter\",\n    input=\"DHSI_food\",\n    output=\"DHSI_foodS\",\n    filter=\"QHFwaf_30m.txt\",\n    nprocs=4,\n)\n\n# Combine the DHSI layers\ngs.run_command(\n    \"r.series\",\n    input=[\"DHSI_shelterS\", \"DHSI_foodS\"],\n    output=\"HSI_tmp\",\n    method=\"minimum\",\n    nprocs=4,\n)\n\n# Patch HSI_temp and build up layers\ngs.run_command(\n    \"r.patch\",\n    input=[\n        \"buildings\",\n        \"railways\",\n        \"roads\",\n        \"traffic\",\n        \"HSI_tmp\",\n    ],\n    output=\"HSI_tmp2\",\n    memory=1000,\n    nprocs=4,\n)\n\n# Assign value 0 to areas with water\ngs.run_command(\"r.mask\", vector=\"Minnesota_bdry\")\ngs.run_command(\"r.mapcalc\", expression=\"HSI_deer = if(NLCD_2016==11,0,HSI_tmp2)\")\n\n# Remove intermediate layers\ngs.run_command(\n    \"g.remove\",\n    flags=\"f\",\n    type=\"raster\",\n    name=[\n        \"buildings\",\n        \"railways\",\n        \"roads\",\n        \"traffic\",\n        \"HSI_tmp\",\n        \"HSI_tmp2\",\n        \"DHSI_shelter\",\n        \"DHSI_food\",\n        \"DHSI_foodS\",\n        \"DHSI_shelterS\",\n        \"deer_tmp\",\n    ],\n)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>All code</span>"
    ]
  },
  {
    "objectID": "all_code.html#spatial-disaggregation",
    "href": "all_code.html#spatial-disaggregation",
    "title": "Appendix A. All code",
    "section": "5: Spatial disaggregation",
    "text": "5: Spatial disaggregation\n# Create base map with with DPA as zones\ngs.run_command(\n    \"v.to.rast\",\n    input=\"deer_densities\",\n    use=\"attr\",\n    attribute_column=\"DPA\",\n    output=\"dpa\",\n)\n\n# Compute sum/average HSI score per DPA\ngs.run_command(\n    \"r.stats.zonal\",\n    base=\"dpa\",\n    cover=\"HSI_deer\",\n    method=\"average\",\n    output=\"HSI_average\",\n)\n\n# Calculate the relative density\ngs.run_command(\n    \"r.mapcalc\",\n    expression=(\"DeerDensities = (HSI_deer/HSI_average)*deer_densities\"),\n    overwrite=True,\n)\n\n# Reclass the 2% highest values to equal the 98 percentile.\np = (\n    gs.read_command(\"r.quantile\", input=\"DeerDensities\", percentiles=98)\n    .split(\":\")[2]\n    .strip()\n)\nexpr = \"DeerDensities = if(DeerDensities &gt; {0}, {0}, DeerDensities)\".format(p)\ngs.run_command(\"r.mapcalc\", expression=expr, overwrite=True)\n\n# Remove intermediate layers\ngs.run_command(\n    \"g.remove\",\n    flags=\"f\",\n    type=[\"raster\", \"vector\"],\n    name=[\n        \"deer_densities\",\n        \"deer_tmp\",\n        \"dpa\",\n        \"HSI_average\",\n    ],\n)\n\n\n\n\n1. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>All code</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "Appendix B. Functions",
    "section": "",
    "text": "All functions used in this tutorial are listed below. Check out the manual pages for more information and examples of how these functions can be used. When going through the examples in this tutorial, it is important to realize that often there are multiple ways to achieve the same.\n\n\ndb.in.ogr: Imports attribute tables in various formats.\ng.region: Manages the boundary definitions for the geographic region.\nr.in.gdal: Imports raster data into a GRASS raster map using GDAL library.\nr.area: Calculates area of clumped areas and remove areas smaller or greater than given threshold.\nr.grow.distance: Generates a raster map containing distances to nearest raster features and/or the value of the nearest non-null cell.\nr.mask: Creates a MASK for limiting raster operation.\nr.mfilter: Performs raster map matrix filter.\nr.null: Manages NULL-values of given raster map, such as replacing null values with an user-defined value.\nr.recode: Recodes categorical raster maps. Here we use it to recodes the land use map (nominal) to suitability maps (ratio).\nr.recode.attr: Recode raster using attribute table (csv file) as input.\ng.remove: Removes data base element files from the user’s current mapset using the search pattern.\nr.resample.stats: Resamples raster map layers to a coarser grid using aggregation.\nr.series: Makes each output cell value a function of the values assigned to the corresponding cells in the input raster map layers.\nr.stats: Generates area statistics for raster map.\nr.stats.zonal: Calculates category or object oriented statistics (accumulator-based statistics).\nr.quantile: Compute quantiles using two passes.\nv.db.join: Joins a database table to a vector map attibute table.\nv.extract: Selects vector features from an existing vector map and creates a new vector map containing only the selected features.\nv.in.ogr: Imports vector data into a GRASS vector map using OGR library.\nv.to.rast: Converts (rasterize) a vector map into a raster map.\n\n\n\n\n\n\n1. Michiel ES, Guidice JH. Monitoring Population Trends of White-Tailed Deer in Minnesota - 2022. Minnesota Department of Natural Resources; 2022:15. https://files.dnr.state.mn.us/wildlife/deer/reports/popmodel/popmodel_2022.pdf",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Functions</span>"
    ]
  }
]